{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2nd DNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0gOpQYQviLF",
        "colab_type": "text"
      },
      "source": [
        "# Version-2\n",
        "### Change1 - Batch Size\n",
        "\n",
        "  For the batch_size comparison, I reset the runtime everytime I was trying new batch. This helped in making a fair comparison and did not increase the epoch number. \n",
        "  - Batch Size: 32  \n",
        "  Max. validation accuracy: 99.27% (4th epoch)\n",
        "  - Batch Size: 64  \n",
        "  Max. validation accuracy: 99.36% (20th epoch)\n",
        "  - Batch Size: 128  \n",
        "    Max. validation accuracy: 99.32% (20th epoch)\n",
        "    \n",
        "  After the above experiment, I decided to go on with batch_size of 64\n",
        "\n",
        "### Change2 - Number of parameters\n",
        "\n",
        "  **Version:2.1**\n",
        "  - Batch Size: 64\n",
        "  - Total number of parameters: 14,402\n",
        "  - Max validation accuracy: 99.19%  (24th epoch)\n",
        "  \n",
        "  \n",
        "  **Version:2.2**\n",
        "  - Batch Size: 64\n",
        "  - Total number of parameters: 7,784\n",
        "  - Max validation accuracy: 98.90%  (20th epoch)\n",
        "\n",
        "### Change3 - Adding Batch Normalization\n",
        "\n",
        "  **Version:2.1**\n",
        "  - Total number of parameters: 14,874\n",
        "  - Max validation accuracy: 99.27%  (23rd epoch)\n",
        "\n",
        "  \n",
        "  **Version:2.2**\n",
        "  - Total number of parameters: 8,120\n",
        "  - Max validation accuracy: 99.07%  (19th epoch)\n",
        "  \n",
        "After training the above 2 models, I decided to go on with version-2.2.    \n",
        "Its clear during the training that the model is overfitting. In next version, I will do changes to avoid overfitting of the model.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### Install Dependencies \n",
        "\n",
        "- To train the following network, we use a framework named Keras.\n",
        "- Keras provides functions for Convolution layers, Activation layers, MaxPooling layer, etc. so we don't need write code for designing such layers. Instead we can focus on creating better network architecture\n",
        "- Following lines of code installs Keras on the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "5701c82f-d0bc-4369-e8c5-43a7888c33c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_6H50FBVsld",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries and Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Numpy for matrices and multi-dimensional array's processing\n",
        "import numpy as np\n",
        "\n",
        "# Import Sequential to write model layer-by-layer in sequence \n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import Flatten layer to flatten feature-map, Dropout to avoid overfitting\n",
        "from keras.layers import Flatten, Dropout, Activation, BatchNormalization\n",
        "\n",
        "# Import Convolution layer to perform convolution on the channels, MaxPooling to reduce dimensions of channel\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "\n",
        "# Import np_utils for one-hot-encoding\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Import hand written dataset of numbers from 0-9\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "The data is loaded in following variables:\n",
        "\n",
        "- X_train: Samples used during training the network\n",
        "- y_train: Corresponding labels for training data\n",
        "- X_test: Samples used for validation after training the network\n",
        "- y_test: Corresponding labels for the validation of network's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "6f193d20-8178-4ef1-8b74-673aa26df0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxIXgp8xYNXF",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Information and Display Data Sample\n",
        "- We have 60000 images in training dataset\n",
        "- We have 10000 images in the testing dataset\n",
        "- Each image's dimension are 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "3f993887-f565-4c86-f004-da0783aa1799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Dimensions of the training dataset images\n",
        "print (X_train.shape)\n",
        "\n",
        "# Dimensions of the testing dataset images\n",
        "print (X_test.shape)\n",
        "\n",
        "# Import python module for plotting the image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Below line is written to display an image in this notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting first image in the training dataset\n",
        "# cmap='gray' displays the data sample in appropriate color space\n",
        "plt.imshow(X_train[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f65dd34e240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKorE7Q0ZOZY",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the dataset\n",
        "- Keras requires the input data in a form of 4D tensor\n",
        "- The first value represents the total number of images in a training/testing dataset\n",
        "- Second and third values are dimensions of an image\n",
        "- Fourth value is the number of channels (1 for grayscale and 3 for RGB)  \n",
        "\n",
        "Thus, the X_train will have a shape of (60000, 28, 28, 1)  \n",
        "and the X_test will have a shape of (1000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yaQcS6aZnte",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the Data\n",
        "- When a Kernel is convolved over an input image, the maximum pixel value in the feature-map depends upon the maximum pixel value in the kernel\n",
        "- Different kernels will have different maximum values and so their corresponding feature-maps will have different maximum values\n",
        "- The feature-map with greater maximum pixel value will be louder while training the network\n",
        "- To avoid biased activations of such kernels, we perform Normalization\n",
        "- For normalization, we first convert the data into float so that we can get all the decimal values\n",
        "- By dividing all the pixels by 255, all the pixel values will be restricted between 0.0 to 1.0. This is how we normalize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFzfX0QqZ9HS",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "8fd921d4-4b97-4f66-99d1-3fe92ec66d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhFS2uM3aDEh",
        "colab_type": "text"
      },
      "source": [
        "### One-Hot Encoding\n",
        "- It is way of representing labels\n",
        "- Instead of using one-single scalar for labels, we use a vector to represent the labels.\n",
        "- The position of the ground-truth is marked as 1 while other positions are marked as 0\n",
        "- The network cannot print out the prediction as 0,1,2,....9\n",
        "- Instead it can activate the neuron associated with these numbers. So, the last layer before activation layer has number of neurons equal to number of classes (in this case 10)\n",
        "- The neuron associated with the number is set as 1 while other neurons are set as 0. Following is the pattern in which encoding is done:  \n",
        "  - Number 0 is encoded as 1000000000  \n",
        "  - Number 1 is encoded as 0100000000  \n",
        "  - Number 2 is encoded as 0010000000  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "  - Number 9 is encoded as 0000000001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yShor8IUaiT9",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels after one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "aacbdb01-bcda-4a8f-d213-337869e818dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spiB8iJDao-w",
        "colab_type": "text"
      },
      "source": [
        "### Model Architecture\n",
        "\n",
        "- Model is defined sequential\n",
        "- The model has convolution, maxpooling, flatten and softmax layers\n",
        "\n",
        "- **Convolution Layer:**\n",
        "  - It is a process of extracting features from a channel using a kernel (feature extractor)\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/5-3ConvolutionSmall.gif?raw=true)\n",
        "\n",
        "- **MaxPooling Layer:**\n",
        "  - It reduces the dimension of an channel. If we use MaxPooling of 2x2, dimension of an channel will become half of input channel\n",
        "  - It only passes the louder pixel value in the next layer\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%203/Files/maxpool.gif?raw=true)\n",
        "\n",
        "- **Softmax Layer:**\n",
        "  - It is like probability\n",
        "  - It gives score of a class between 0 and 1\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/softmax.png?raw=true)\n",
        "\n",
        "- **Flatten Layer:**\n",
        "  - It flattens the input dimension\n",
        "  - Multiple 2D channels are converted into a vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEuk3hYDlRLA",
        "colab_type": "text"
      },
      "source": [
        "## Version - 2.1 with 14,402 parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "26f8dc52-40c0-4ba5-db02-3f366fcda5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', name='conv_2'))                          # Layer 2: Input:26x26x10  |  Kernels:(3x3x10)x16  |  Output:24x24x16  |  Receptive Field:5x5  \n",
        "model.add(Convolution2D(18, 3, 3, activation='relu', name='conv_3'))                          # Layer 3: Input:24x24x16  |  Kernels:(3x3x16)x18  |  Output:22x22x18  |  Receptive Field:7x7\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                      # Layer 4: Input:22x22x18  |  Kernels:(1x1x18)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         # Layer 5: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', name='conv_5'))                          # Layer 6: Input:11x11x10  |  Kernels:(3x3x10)x16  |  Output:9x9x16  |  Receptive Field:16x16 \n",
        "model.add(Convolution2D(18, 3, 3, activation='relu', name='conv_6'))                          # Layer 7: Input:09x09x16  |  Kernels:(3x3x16)x18  |  Output:7x7x18  |  Receptive Field:18x18 \n",
        "model.add(Convolution2D(20, 3, 3, activation='relu', name='conv_7'))                          # Layer 8: Input:07x07x18  |  Kernels:(3x3x18)x20  |  Output:5x5x20  |  Receptive Field:20x20 \n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      # Layer 9: Input:5x5x20    |  Kernels:(1x1x20)x10  |  Output:5x5x10  |  Receptive Field:22x22\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                # Layer 10: Input:5x5x10   |  Kernels:(5x5x10)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                          # Layer 11: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                              # Layer 12: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 22, 22, 18)        2610      \n",
            "_________________________________________________________________\n",
            "conv_4_1x1 (Conv2D)          (None, 22, 22, 10)        190       \n",
            "_________________________________________________________________\n",
            "MP (MaxPooling2D)            (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 7, 7, 18)          2610      \n",
            "_________________________________________________________________\n",
            "conv_7 (Conv2D)              (None, 5, 5, 20)          3260      \n",
            "_________________________________________________________________\n",
            "conv_8_1x1 (Conv2D)          (None, 5, 5, 10)          210       \n",
            "_________________________________________________________________\n",
            "conv_9 (Conv2D)              (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,402\n",
            "Trainable params: 14,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(18, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(18, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2PEwIVMbZFI",
        "colab_type": "text"
      },
      "source": [
        "### Compile Model\n",
        "- **Loss Function:**\n",
        "  - Loss function is used to calculate the error  between the prediction and actual label\n",
        "  - Using optimizer, we reduce the value of loss function as much as possible\n",
        "  - [More about cross-entropy loss](https://towardsdatascience.com/demystifying-cross-entropy-e80e3ad54a8)\n",
        "\n",
        "- **Optimizer:**\n",
        "  - Optimizers decide by how much value the weights should be changed while training the network \n",
        "  - Adam (Adaptive Moment Estimation) uses a complicated exponential decay that consists of the average and the variance of the previous steps.\n",
        "  - [More about optimizers](http://ruder.io/optimizing-gradient-descent/index.html#rmsprop)\n",
        "  \n",
        "- **Metrics:**\n",
        "  - The training progress of the model is calculated in terms of metrics used\n",
        "  - Here, we monitor the progress of the training in terms of accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDAUQu6CbbZD",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model\n",
        "- Model is trained on training images and its labels\n",
        "- Model is trained on batch_size of 32 that is, 32 images are passed through the network at a time\n",
        "- The model is trained on the dataset for 10 iterations (epochs)\n",
        "- Verbose 1 means it will print all the training information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzyuqACn35qx",
        "colab_type": "code",
        "outputId": "d8da3509-cc27-49a9-e678-fc9d63bf166c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 12s 200us/step - loss: 0.3140 - acc: 0.8969 - val_loss: 0.0964 - val_acc: 0.9711\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0944 - acc: 0.9712 - val_loss: 0.0578 - val_acc: 0.9816\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0725 - acc: 0.9778 - val_loss: 0.0602 - val_acc: 0.9815\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0588 - acc: 0.9821 - val_loss: 0.0415 - val_acc: 0.9873\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0507 - acc: 0.9848 - val_loss: 0.0527 - val_acc: 0.9837\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0443 - acc: 0.9861 - val_loss: 0.0557 - val_acc: 0.9833\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0401 - acc: 0.9873 - val_loss: 0.0341 - val_acc: 0.9885\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0361 - acc: 0.9889 - val_loss: 0.0345 - val_acc: 0.9890\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0320 - acc: 0.9901 - val_loss: 0.0339 - val_acc: 0.9900\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0294 - acc: 0.9905 - val_loss: 0.0314 - val_acc: 0.9901\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0282 - acc: 0.9912 - val_loss: 0.0282 - val_acc: 0.9904\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0256 - acc: 0.9914 - val_loss: 0.0327 - val_acc: 0.9898\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0314 - val_acc: 0.9906\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0279 - val_acc: 0.9905\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0215 - acc: 0.9932 - val_loss: 0.0337 - val_acc: 0.9890\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0190 - acc: 0.9938 - val_loss: 0.0253 - val_acc: 0.9914\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0178 - acc: 0.9939 - val_loss: 0.0358 - val_acc: 0.9888\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.0332 - val_acc: 0.9893\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0165 - acc: 0.9947 - val_loss: 0.0356 - val_acc: 0.9889\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0259 - val_acc: 0.9917\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0144 - acc: 0.9950 - val_loss: 0.0422 - val_acc: 0.9898\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0135 - acc: 0.9952 - val_loss: 0.0320 - val_acc: 0.9910\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0308 - val_acc: 0.9915\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0333 - val_acc: 0.9919\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.0390 - val_acc: 0.9907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65da040b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo8V5qJ1O7Oe",
        "colab_type": "text"
      },
      "source": [
        "## Version - 2.1 with BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d507573-e399-4dc0-dce0-fa7a4be31f4b",
        "id": "8YNdFxUQPBLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1028
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(BatchNormalization())                                                               # Layer 2: Batch Normalization (BN)\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', name='conv_2'))                          # Layer 3: Input:26x26x10  |  Kernels:(3x3x10)x16  |  Output:24x24x16  |  Receptive Field:5x5  \n",
        "model.add(BatchNormalization())                                                               # Layer 4: Batch Normalization (BN)\n",
        "model.add(Convolution2D(18, 3, 3, activation='relu', name='conv_3'))                          # Layer 5: Input:24x24x16  |  Kernels:(3x3x16)x18  |  Output:22x22x18  |  Receptive Field:7x7\n",
        "model.add(BatchNormalization())                                                               # Layer 6: Batch Normalization (BN)\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                      # Layer 7: Input:22x22x18  |  Kernels:(1x1x18)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         # Layer 8: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', name='conv_5'))                          # Layer 9: Input:11x11x10  |  Kernels:(3x3x10)x16  |  Output:9x9x16  |  Receptive Field:16x16 \n",
        "model.add(BatchNormalization())                                                               # Layer 10: Batch Normalization (BN)\n",
        "model.add(Convolution2D(18, 3, 3, activation='relu', name='conv_6'))                          # Layer 11: Input:09x09x16 |  Kernels:(3x3x16)x18  |  Output:7x7x18  |  Receptive Field:18x18 \n",
        "model.add(BatchNormalization())                                                               # Layer 12: Batch Normalization (BN)\n",
        "model.add(Convolution2D(20, 3, 3, activation='relu', name='conv_7'))                          # Layer 13: Input:07x07x18 |  Kernels:(3x3x18)x20  |  Output:5x5x20  |  Receptive Field:20x20 \n",
        "model.add(BatchNormalization())                                                               # Layer 14: Batch Normalization (BN)\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      # Layer 15: Input:5x5x20   |  Kernels:(1x1x20)x10  |  Output:5x5x20  |  Receptive Field:22x22\n",
        "model.add(BatchNormalization())                                                               # Layer 16: Batch Normalization (BN)\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                # Layer 17: Input:5x5x20   |  Kernels:(5x5x20)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                          # Layer 18: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                              # Layer 19: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(18, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(18, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 22, 22, 18)        2610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 22, 22, 18)        72        \n",
            "_________________________________________________________________\n",
            "conv_4_1x1 (Conv2D)          (None, 22, 22, 10)        190       \n",
            "_________________________________________________________________\n",
            "MP (MaxPooling2D)            (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 7, 7, 18)          2610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 7, 7, 18)          72        \n",
            "_________________________________________________________________\n",
            "conv_7 (Conv2D)              (None, 5, 5, 20)          3260      \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 5, 5, 20)          80        \n",
            "_________________________________________________________________\n",
            "conv_8_1x1 (Conv2D)          (None, 5, 5, 10)          210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_9 (Conv2D)              (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,874\n",
            "Trainable params: 14,638\n",
            "Non-trainable params: 236\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dauHtJf9PBL2",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0523897a-f6e6-4647-d83f-a2753d2eed72",
        "id": "n1OPe-0dPBL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 0.2139 - acc: 0.9352 - val_loss: 0.0640 - val_acc: 0.9803\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0544 - acc: 0.9832 - val_loss: 0.0449 - val_acc: 0.9857\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0402 - acc: 0.9876 - val_loss: 0.0461 - val_acc: 0.9864\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0330 - acc: 0.9897 - val_loss: 0.0362 - val_acc: 0.9882\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0273 - acc: 0.9915 - val_loss: 0.0341 - val_acc: 0.9896\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.0240 - acc: 0.9923 - val_loss: 0.0351 - val_acc: 0.9890\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0230 - acc: 0.9927 - val_loss: 0.0293 - val_acc: 0.9911\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0308 - val_acc: 0.9896\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0326 - val_acc: 0.9900\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0447 - val_acc: 0.9869\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0364 - val_acc: 0.9884\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0140 - acc: 0.9951 - val_loss: 0.0953 - val_acc: 0.9725\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0262 - val_acc: 0.9919\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0274 - val_acc: 0.9923\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0249 - val_acc: 0.9927\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0293 - val_acc: 0.9916\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0413 - val_acc: 0.9900\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0086 - acc: 0.9971 - val_loss: 0.0286 - val_acc: 0.9909\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0336 - val_acc: 0.9907\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0284 - val_acc: 0.9916\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0311 - val_acc: 0.9911\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0454 - val_acc: 0.9871\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0310 - val_acc: 0.9930\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0057 - acc: 0.9979 - val_loss: 0.0357 - val_acc: 0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6590024048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAArQ_TNQTfR",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clz-fRVIPiDS",
        "colab_type": "text"
      },
      "source": [
        "### Version - 2.2: Model with 7784 parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kjG9QWpqMhV",
        "colab_type": "code",
        "outputId": "a54caa7d-4091-4e35-df43-e64766cea575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2'))                          # Layer 2: Input:26x26x10  |  Kernels:(3x3x10)x10  |  Output:24x24x10  |  Receptive Field:5x5  \n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3'))                          # Layer 3: Input:24x24x10  |  Kernels:(3x3x10)x12  |  Output:22x22x12  |  Receptive Field:7x7\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                      # Layer 4: Input:22x22x12  |  Kernels:(1x1x12)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         # Layer 5: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5'))                          # Layer 6: Input:11x11x10  |  Kernels:(3x3x10)x10  |  Output:9x9x10  |  Receptive Field:16x16 \n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6'))                          # Layer 7: Input:09x09x10  |  Kernels:(3x3x10)x10  |  Output:7x7x10  |  Receptive Field:18x18 \n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7'))                          # Layer 8: Input:07x07x10  |  Kernels:(3x3x10)x12  |  Output:5x5x12  |  Receptive Field:20x20 \n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      # Layer 9: Input:5x5x12    |  Kernels:(1x1x12)x10  |  Output:5x5x10  |  Receptive Field:22x22\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                # Layer 10: Input:5x5x10   |  Kernels:(5x5x10)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                          # Layer 11: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                              # Layer 12: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 24, 24, 10)        910       \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 22, 22, 12)        1092      \n",
            "_________________________________________________________________\n",
            "conv_4_1x1 (Conv2D)          (None, 22, 22, 10)        130       \n",
            "_________________________________________________________________\n",
            "MP (MaxPooling2D)            (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "conv_7 (Conv2D)              (None, 5, 5, 12)          1092      \n",
            "_________________________________________________________________\n",
            "conv_8_1x1 (Conv2D)          (None, 5, 5, 10)          130       \n",
            "_________________________________________________________________\n",
            "conv_9 (Conv2D)              (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_13 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,784\n",
            "Trainable params: 7,784\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP3DTFKMqQQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vifw6UboqQyK",
        "colab_type": "code",
        "outputId": "cfe98abf-8e1e-4d09-c2f8-6e88c655da95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 9s 150us/step - loss: 0.3727 - acc: 0.8813 - val_loss: 0.1220 - val_acc: 0.9601\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.1142 - acc: 0.9647 - val_loss: 0.0878 - val_acc: 0.9714\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0861 - acc: 0.9736 - val_loss: 0.1023 - val_acc: 0.9675\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0724 - acc: 0.9769 - val_loss: 0.0644 - val_acc: 0.9793\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0654 - acc: 0.9797 - val_loss: 0.0661 - val_acc: 0.9784\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0582 - acc: 0.9819 - val_loss: 0.0700 - val_acc: 0.9772\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0526 - acc: 0.9831 - val_loss: 0.0571 - val_acc: 0.9823\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0491 - acc: 0.9843 - val_loss: 0.0472 - val_acc: 0.9843\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0466 - acc: 0.9854 - val_loss: 0.0445 - val_acc: 0.9851\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0426 - acc: 0.9865 - val_loss: 0.0495 - val_acc: 0.9842\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0401 - acc: 0.9872 - val_loss: 0.0431 - val_acc: 0.9859\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0390 - acc: 0.9870 - val_loss: 0.0429 - val_acc: 0.9869\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0372 - acc: 0.9881 - val_loss: 0.0409 - val_acc: 0.9863\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0445 - val_acc: 0.9862\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0326 - acc: 0.9897 - val_loss: 0.0479 - val_acc: 0.9868\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0319 - acc: 0.9895 - val_loss: 0.0388 - val_acc: 0.9877\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0291 - acc: 0.9909 - val_loss: 0.0433 - val_acc: 0.9856\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0300 - acc: 0.9902 - val_loss: 0.0427 - val_acc: 0.9875\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.0403 - val_acc: 0.9878\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.0393 - val_acc: 0.9890\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0253 - acc: 0.9921 - val_loss: 0.0394 - val_acc: 0.9877\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0397 - val_acc: 0.9876\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0352 - val_acc: 0.9890\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0216 - acc: 0.9927 - val_loss: 0.0406 - val_acc: 0.9870\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0211 - acc: 0.9932 - val_loss: 0.0443 - val_acc: 0.9869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65943c41d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SDuRDmjPuD-",
        "colab_type": "text"
      },
      "source": [
        "### Version - 2.2 with BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KR_t_XV9rk",
        "colab_type": "code",
        "outputId": "1c027794-bd1a-4632-9ddd-53f7966b8037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1028
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(BatchNormalization())                                                               # Layer 2: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2'))                          # Layer 3: Input:26x26x10  |  Kernels:(3x3x10)x10  |  Output:24x24x10  |  Receptive Field:5x5  \n",
        "model.add(BatchNormalization())                                                               # Layer 4: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3'))                          # Layer 5: Input:24x24x64  |  Kernels:(3x3x10)x12  |  Output:22x22x12  |  Receptive Field:7x7\n",
        "model.add(BatchNormalization())                                                               # Layer 6: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                      # Layer 7: Input:22x22x12  |  Kernels:(1x1x12)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         # Layer 8: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "model.add(BatchNormalization())                                                               # Layer 9: Batch Normalization\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5'))                          # Layer 10: Input:11x11x10  |  Kernels:(3x3x10)x10  |  Output:9x9x10  |  Receptive Field:16x16 \n",
        "model.add(BatchNormalization())                                                               # Layer 11: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6'))                          # Layer 12: Input:09x09x10  |  Kernels:(3x3x10)x10  |  Output:7x7x10  |  Receptive Field:18x18 \n",
        "model.add(BatchNormalization())                                                               # Layer 13: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7'))                          # Layer 14: Input:07x07x10  |  Kernels:(3x3x10)x12  |  Output:5x5x12  |  Receptive Field:20x20 \n",
        "model.add(BatchNormalization())                                                               # Layer 15: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      # Layer 16: Input:5x5x12    |  Kernels:(1x1x12)x10  |  Output:5x5x10  |  Receptive Field:22x22\n",
        "model.add(BatchNormalization())                                                               # Layer 17: Batch Normalization\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                # Layer 18: Input:5x5x10   |  Kernels:(5x5x10)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                          # Layer 19: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                              # Layer 20: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 24, 24, 10)        910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 22, 22, 12)        1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 22, 22, 12)        48        \n",
            "_________________________________________________________________\n",
            "conv_4_1x1 (Conv2D)          (None, 22, 22, 10)        130       \n",
            "_________________________________________________________________\n",
            "MP (MaxPooling2D)            (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 9, 9, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_7 (Conv2D)              (None, 5, 5, 12)          1092      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 5, 5, 12)          48        \n",
            "_________________________________________________________________\n",
            "conv_8_1x1 (Conv2D)          (None, 5, 5, 10)          130       \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_9 (Conv2D)              (None, 1, 1, 10)          2510      \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,120\n",
            "Trainable params: 7,952\n",
            "Non-trainable params: 168\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MSbJEfeWDhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLHrZSAtWEFa",
        "colab_type": "code",
        "outputId": "2dc035c2-2b96-4a64-a0a1-a4b86d2f6bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 14s 237us/step - loss: 0.3063 - acc: 0.9049 - val_loss: 0.0658 - val_acc: 0.9795\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0653 - acc: 0.9806 - val_loss: 0.0451 - val_acc: 0.9860\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0498 - acc: 0.9846 - val_loss: 0.0398 - val_acc: 0.9873\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0417 - acc: 0.9867 - val_loss: 0.0415 - val_acc: 0.9854\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0344 - acc: 0.9895 - val_loss: 0.0422 - val_acc: 0.9866\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0322 - acc: 0.9899 - val_loss: 0.0340 - val_acc: 0.9898\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0287 - acc: 0.9909 - val_loss: 0.0296 - val_acc: 0.9904\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 13s 208us/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0325 - val_acc: 0.9901\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0340 - val_acc: 0.9898\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0393 - val_acc: 0.9872\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0212 - acc: 0.9931 - val_loss: 0.0379 - val_acc: 0.9883\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0385 - val_acc: 0.9894\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0188 - acc: 0.9935 - val_loss: 0.0348 - val_acc: 0.9889\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.0337 - val_acc: 0.9900\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0446 - val_acc: 0.9861\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0146 - acc: 0.9952 - val_loss: 0.0396 - val_acc: 0.9877\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0136 - acc: 0.9954 - val_loss: 0.0329 - val_acc: 0.9899\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0141 - acc: 0.9949 - val_loss: 0.0386 - val_acc: 0.9886\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0334 - val_acc: 0.9907\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0329 - val_acc: 0.9903\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.0383 - val_acc: 0.9897\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0105 - acc: 0.9960 - val_loss: 0.0370 - val_acc: 0.9898\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0385 - val_acc: 0.9892\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0365 - val_acc: 0.9903\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0388 - val_acc: 0.9902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65921ed160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29mkUmABswfz",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    }
  ]
}