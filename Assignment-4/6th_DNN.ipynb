{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6th DNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0gOpQYQviLF",
        "colab_type": "text"
      },
      "source": [
        "# Version-6\n",
        "\n",
        "### Change -Reducing parameters by removing biases\n",
        "\n",
        "Summary:\n",
        "- Total parameters: 8026 - 99.43% (22nd epoch)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### Install Dependencies \n",
        "\n",
        "- To train the following network, we use a framework named Keras.\n",
        "- Keras provides functions for Convolution layers, Activation layers, MaxPooling layer, etc. so we don't need write code for designing such layers. Instead we can focus on creating better network architecture\n",
        "- Following lines of code installs Keras on the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "93b48705-65ec-4e65-b911-ac6467b31504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_6H50FBVsld",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries and Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Numpy for matrices and multi-dimensional array's processing\n",
        "import numpy as np\n",
        "\n",
        "# Import Sequential to write model layer-by-layer in sequence \n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import Flatten layer to flatten feature-map, Dropout to avoid overfitting\n",
        "from keras.layers import Flatten, Dropout, Activation, BatchNormalization\n",
        "\n",
        "# Import Convolution layer to perform convolution on the channels, MaxPooling to reduce dimensions of channel\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "\n",
        "# Import np_utils for one-hot-encoding\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Import hand written dataset of numbers from 0-9\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "The data is loaded in following variables:\n",
        "\n",
        "- X_train: Samples used during training the network\n",
        "- y_train: Corresponding labels for training data\n",
        "- X_test: Samples used for validation after training the network\n",
        "- y_test: Corresponding labels for the validation of network's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxIXgp8xYNXF",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Information and Display Data Sample\n",
        "- We have 60000 images in training dataset\n",
        "- We have 10000 images in the testing dataset\n",
        "- Each image's dimension are 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "c7e3c014-0cf8-4334-9726-22011f4455fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Dimensions of the training dataset images\n",
        "print (X_train.shape)\n",
        "\n",
        "# Dimensions of the testing dataset images\n",
        "print (X_test.shape)\n",
        "\n",
        "# Import python module for plotting the image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Below line is written to display an image in this notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting first image in the training dataset\n",
        "# cmap='gray' displays the data sample in appropriate color space\n",
        "plt.imshow(X_train[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbe75dbacf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADgdJREFUeJzt3X9sXfV5x/HPs9D8QRoIXjUTpWFp\nIhQUIuZOJkwoGkXM5YeCggGhWkLKRBT3j1ii0hQNZX8MNAVFg2RqBKrsqqHJ1KWZBCghqpp0CZBO\nTBEmhF9mKQylqi2TFAWTH/zIHD/74x53Lvh+r3Pvufdc+3m/JMv3nuecex4d5ZPz8/pr7i4A8fxJ\n0Q0AKAbhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1GWNXJmZ8TghUGfublOZr6Y9v5ndYWbH\nzex9M3ukls8C0FhW7bP9ZjZL0m8kdUgalPSqpC53H0gsw54fqLNG7PlXSHrf3T9w9wuSfi5pdQ2f\nB6CBagn/Akm/m/B+MJv2R8ys28z6zay/hnUByFndL/i5e5+kPonDfqCZ1LLnH5K0cML7b2bTAEwD\ntYT/VUnXmtm3zGy2pO9J2ptPWwDqrerDfncfNbMeSfslzZK03d3fya0zAHVV9a2+qlbGOT9Qdw15\nyAfA9EX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUFUP0S1JZnZC\n0llJFyWNunt7Hk0hP7NmzUrWr7zyyrquv6enp2zt8ssvTy67dOnSZH39+vXJ+pNPPlm21tXVlVz2\n888/T9Y3b96crD/22GPJejOoKfyZW939oxw+B0ADcdgPBFVr+F3SATN7zcy682gIQGPUeti/0t2H\nzOzPJP3KzP7b3Q9PnCH7T4H/GIAmU9Oe392Hst+nJD0vacUk8/S5ezsXA4HmUnX4zWyOmc0dfy3p\nu5LezqsxAPVVy2F/q6TnzWz8c/7N3X+ZS1cA6q7q8Lv7B5L+IsdeZqxrrrkmWZ89e3ayfvPNNyfr\nK1euLFubN29ectn77rsvWS/S4OBgsr5t27ZkvbOzs2zt7NmzyWXfeOONZP3ll19O1qcDbvUBQRF+\nICjCDwRF+IGgCD8QFOEHgjJ3b9zKzBq3sgZqa2tL1g8dOpSs1/trtc1qbGwsWX/ooYeS9XPnzlW9\n7uHh4WT9448/TtaPHz9e9brrzd1tKvOx5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoLjPn4OWlpZk\n/ciRI8n64sWL82wnV5V6HxkZSdZvvfXWsrULFy4kl436/EOtuM8PIInwA0ERfiAowg8ERfiBoAg/\nEBThB4LKY5Te8E6fPp2sb9iwIVlftWpVsv76668n65X+hHXKsWPHkvWOjo5k/fz588n69ddfX7b2\n8MMPJ5dFfbHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgKn6f38y2S1ol6ZS7L8+mtUjaLWmRpBOS\nHnD39B8618z9Pn+trrjiimS90nDSvb29ZWtr165NLvvggw8m67t27UrW0Xzy/D7/TyXd8aVpj0g6\n6O7XSjqYvQcwjVQMv7sflvTlR9hWS9qRvd4h6Z6c+wJQZ9We87e6+/h4Rx9Kas2pHwANUvOz/e7u\nqXN5M+uW1F3regDkq9o9/0kzmy9J2e9T5WZ09z53b3f39irXBaAOqg3/XklrstdrJO3Jpx0AjVIx\n/Ga2S9J/SVpqZoNmtlbSZkkdZvaepL/J3gOYRiqe87t7V5nSbTn3EtaZM2dqWv6TTz6petl169Yl\n67t3707Wx8bGql43isUTfkBQhB8IivADQRF+ICjCDwRF+IGgGKJ7BpgzZ07Z2gsvvJBc9pZbbknW\n77zzzmT9wIEDyToajyG6ASQRfiAowg8ERfiBoAg/EBThB4Ii/EBQ3Oef4ZYsWZKsHz16NFkfGRlJ\n1l988cVkvb+/v2zt6aefTi7byH+bMwn3+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNznD66zszNZ\nf+aZZ5L1uXPnVr3ujRs3Jus7d+5M1oeHh5P1qLjPDyCJ8ANBEX4gKMIPBEX4gaAIPxAU4QeCqnif\n38y2S1ol6ZS7L8+mPSppnaTfZ7NtdPdfVFwZ9/mnneXLlyfrW7duTdZvu636kdx7e3uT9U2bNiXr\nQ0NDVa97OsvzPv9PJd0xyfR/cfe27Kdi8AE0l4rhd/fDkk43oBcADVTLOX+Pmb1pZtvN7KrcOgLQ\nENWG/0eSlkhqkzQsaUu5Gc2s28z6zaz8H3MD0HBVhd/dT7r7RXcfk/RjSSsS8/a5e7u7t1fbJID8\nVRV+M5s/4W2npLfzaQdAo1xWaQYz2yXpO5K+YWaDkv5R0nfMrE2SSzoh6ft17BFAHfB9ftRk3rx5\nyfrdd99dtlbpbwWYpW9XHzp0KFnv6OhI1mcqvs8PIInwA0ERfiAowg8ERfiBoAg/EBS3+lCYL774\nIlm/7LL0Yyijo6PJ+u2331629tJLLyWXnc641QcgifADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX7E\ndsMNNyTr999/f7J+4403lq1Vuo9fycDAQLJ++PDhmj5/pmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK\n8ANBcZ9/hlu6dGmy3tPTk6zfe++9yfrVV199yT1N1cWLF5P14eHhZH1sbCzPdmYc9vxAUIQfCIrw\nA0ERfiAowg8ERfiBoAg/EFTF+/xmtlDSTkmtklxSn7v/0MxaJO2WtEjSCUkPuPvH9Ws1rkr30ru6\nusrWKt3HX7RoUTUt5aK/vz9Z37RpU7K+d+/ePNsJZyp7/lFJf+fuyyT9laT1ZrZM0iOSDrr7tZIO\nZu8BTBMVw+/uw+5+NHt9VtK7khZIWi1pRzbbDkn31KtJAPm7pHN+M1sk6duSjkhqdffx5ys/VOm0\nAMA0MeVn+83s65KelfQDdz9j9v/Dgbm7lxuHz8y6JXXX2iiAfE1pz29mX1Mp+D9z9+eyySfNbH5W\nny/p1GTLunufu7e7e3seDQPIR8XwW2kX/xNJ77r71gmlvZLWZK/XSNqTf3sA6qXiEN1mtlLSryW9\nJWn8O5IbVTrv/3dJ10j6rUq3+k5X+KyQQ3S3tqYvhyxbtixZf+qpp5L166677pJ7ysuRI0eS9See\neKJsbc+e9P6Cr+RWZ6pDdFc853f3/5RU7sNuu5SmADQPnvADgiL8QFCEHwiK8ANBEX4gKMIPBMWf\n7p6ilpaWsrXe3t7ksm1tbcn64sWLq+opD6+88kqyvmXLlmR9//79yfpnn312yT2hMdjzA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQYe7z33TTTcn6hg0bkvUVK1aUrS1YsKCqnvLy6aeflq1t27Ytuezj\njz+erJ8/f76qntD82PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFBh7vN3dnbWVK/FwMBAsr5v375k\nfXR0NFlPfed+ZGQkuSziYs8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu6dnMFsoaaekVkkuqc/d\nf2hmj0paJ+n32awb3f0XFT4rvTIANXN3m8p8Uwn/fEnz3f2omc2V9JqkeyQ9IOmcuz851aYIP1B/\nUw1/xSf83H1Y0nD2+qyZvSup2D9dA6Bml3TOb2aLJH1b0pFsUo+ZvWlm283sqjLLdJtZv5n119Qp\ngFxVPOz/w4xmX5f0sqRN7v6cmbVK+kil6wD/pNKpwUMVPoPDfqDOcjvnlyQz+5qkfZL2u/vWSeqL\nJO1z9+UVPofwA3U21fBXPOw3M5P0E0nvTgx+diFwXKekty+1SQDFmcrV/pWSfi3pLUlj2eSNkrok\ntal02H9C0vezi4Opz2LPD9RZrof9eSH8QP3ldtgPYGYi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gKMIPBNXoIbo/kvTbCe+/kU1rRs3aW7P2JdFbtfLs7c+nOmNDv8//\nlZWb9bt7e2ENJDRrb83al0Rv1SqqNw77gaAIPxBU0eHvK3j9Kc3aW7P2JdFbtQrprdBzfgDFKXrP\nD6AghYTfzO4ws+Nm9r6ZPVJED+WY2Qkze8vMjhU9xFg2DNopM3t7wrQWM/uVmb2X/Z50mLSCenvU\nzIaybXfMzO4qqLeFZvaimQ2Y2Ttm9nA2vdBtl+irkO3W8MN+M5sl6TeSOiQNSnpVUpe7DzS0kTLM\n7ISkdncv/J6wmf21pHOSdo6PhmRm/yzptLtvzv7jvMrd/75JentUlzhyc516Kzey9N+qwG2X54jX\neShiz79C0vvu/oG7X5D0c0mrC+ij6bn7YUmnvzR5taQd2esdKv3jabgyvTUFdx9296PZ67OSxkeW\nLnTbJfoqRBHhXyDpdxPeD6q5hvx2SQfM7DUz6y66mUm0ThgZ6UNJrUU2M4mKIzc30pdGlm6abVfN\niNd544LfV61097+UdKek9dnhbVPy0jlbM92u+ZGkJSoN4zYsaUuRzWQjSz8r6QfufmZirchtN0lf\nhWy3IsI/JGnhhPffzKY1BXcfyn6fkvS8SqcpzeTk+CCp2e9TBffzB+5+0t0vuvuYpB+rwG2XjSz9\nrKSfuftz2eTCt91kfRW13YoI/6uSrjWzb5nZbEnfk7S3gD6+wszmZBdiZGZzJH1XzTf68F5Ja7LX\nayTtKbCXP9IsIzeXG1laBW+7phvx2t0b/iPpLpWu+P+PpH8ooocyfS2W9Eb2807RvUnapdJh4P+q\ndG1kraQ/lXRQ0nuS/kNSSxP19q8qjeb8pkpBm19QbytVOqR/U9Kx7Oeuorddoq9CthtP+AFBccEP\nCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ/weCC5r/92q6mAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKorE7Q0ZOZY",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the dataset\n",
        "- Keras requires the input data in a form of 4D tensor\n",
        "- The first value represents the total number of images in a training/testing dataset\n",
        "- Second and third values are dimensions of an image\n",
        "- Fourth value is the number of channels (1 for grayscale and 3 for RGB)  \n",
        "\n",
        "Thus, the X_train will have a shape of (60000, 28, 28, 1)  \n",
        "and the X_test will have a shape of (1000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yaQcS6aZnte",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the Data\n",
        "- When a Kernel is convolved over an input image, the maximum pixel value in the feature-map depends upon the maximum pixel value in the kernel\n",
        "- Different kernels will have different maximum values and so their corresponding feature-maps will have different maximum values\n",
        "- The feature-map with greater maximum pixel value will be louder while training the network\n",
        "- To avoid biased activations of such kernels, we perform Normalization\n",
        "- For normalization, we first convert the data into float so that we can get all the decimal values\n",
        "- By dividing all the pixels by 255, all the pixel values will be restricted between 0.0 to 1.0. This is how we normalize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFzfX0QqZ9HS",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "6bb22299-f123-4948-d00f-0f4657f63e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhFS2uM3aDEh",
        "colab_type": "text"
      },
      "source": [
        "### One-Hot Encoding\n",
        "- It is way of representing labels\n",
        "- Instead of using one-single scalar for labels, we use a vector to represent the labels.\n",
        "- The position of the ground-truth is marked as 1 while other positions are marked as 0\n",
        "- The network cannot print out the prediction as 0,1,2,....9\n",
        "- Instead it can activate the neuron associated with these numbers. So, the last layer before activation layer has number of neurons equal to number of classes (in this case 10)\n",
        "- The neuron associated with the number is set as 1 while other neurons are set as 0. Following is the pattern in which encoding is done:  \n",
        "  - Number 0 is encoded as 1000000000  \n",
        "  - Number 1 is encoded as 0100000000  \n",
        "  - Number 2 is encoded as 0010000000  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "  - Number 9 is encoded as 0000000001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yShor8IUaiT9",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels after one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "a7ce2406-26c9-4fea-b6e4-9ea115283e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spiB8iJDao-w",
        "colab_type": "text"
      },
      "source": [
        "### Model Architecture\n",
        "\n",
        "- Model is defined sequential\n",
        "- The model has convolution, maxpooling, flatten and softmax layers\n",
        "\n",
        "- **Convolution Layer:**\n",
        "  - It is a process of extracting features from a channel using a kernel (feature extractor)\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/5-3ConvolutionSmall.gif?raw=true)\n",
        "\n",
        "- **MaxPooling Layer:**\n",
        "  - It reduces the dimension of an channel. If we use MaxPooling of 2x2, dimension of an channel will become half of input channel\n",
        "  - It only passes the louder pixel value in the next layer\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%203/Files/maxpool.gif?raw=true)\n",
        "\n",
        "- **Softmax Layer:**\n",
        "  - It is like probability\n",
        "  - It gives score of a class between 0 and 1\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/softmax.png?raw=true)\n",
        "\n",
        "- **Flatten Layer:**\n",
        "  - It flattens the input dimension\n",
        "  - Multiple 2D channels are converted into a vector "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KR_t_XV9rk",
        "colab_type": "code",
        "outputId": "2fbae8d5-32ae-4bff-8fd4-a28b28d45b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1179
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "drop = 0.2\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1', use_bias=False))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(BatchNormalization())                                                                               # Layer 2: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2', use_bias=False))                          # Layer 3: Input:26x26x10  |  Kernels:(3x3x10)x10  |  Output:24x24x10  |  Receptive Field:5x5  \n",
        "model.add(BatchNormalization())                                                                               # Layer 4: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3', use_bias=False))                          # Layer 5: Input:24x24x64  |  Kernels:(3x3x10)x12  |  Output:22x22x12  |  Receptive Field:7x7\n",
        "model.add(BatchNormalization())                                                                               # Layer 6: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1', use_bias=False))                      # Layer 7: Input:22x22x12  |  Kernels:(1x1x12)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                                         # Layer 8: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "model.add(BatchNormalization())                                                                               # Layer 9: Batch Normalization\n",
        "model.add(Dropout(drop))                                                                                      # Layer 10: Dropout Layer\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5', use_bias=False))                          # Layer 11: Input:11x11x10  |  Kernels:(3x3x10)x10  |  Output:9x9x10  |  Receptive Field:16x16 \n",
        "model.add(BatchNormalization())                                                                               # Layer 12: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6', use_bias=False))                          # Layer 13: Input:09x09x10  |  Kernels:(3x3x10)x10  |  Output:7x7x10  |  Receptive Field:18x18 \n",
        "model.add(BatchNormalization())                                                                               # Layer 14: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7', use_bias=False))                          # Layer 15: Input:07x07x10  |  Kernels:(3x3x10)x12  |  Output:5x5x12  |  Receptive Field:20x20 \n",
        "model.add(BatchNormalization())                                                                               # Layer 16: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1', use_bias=False))                      # Layer 17: Input:5x5x12    |  Kernels:(1x1x12)x10  |  Output:5x5x10  |  Receptive Field:22x22\n",
        "model.add(BatchNormalization())                                                                               # Layer 18: Batch Normalization\n",
        "model.add(Dropout(drop))                                                                                      # Layer 19: Dropout Layer\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9', use_bias=False))                                                # Layer 20: Input:5x5x10   |  Kernels:(5x5x10)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                                          # Layer 21: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                                              # Layer 22: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\", use_bias=False)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\", use_bias=False)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\", use_bias=False)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\", use_bias=False)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\", use_bias=False)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 26, 26, 10)        90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 24, 24, 10)        900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 22, 22, 12)        1080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 12)        48        \n",
            "_________________________________________________________________\n",
            "conv_4_1x1 (Conv2D)          (None, 22, 22, 10)        120       \n",
            "_________________________________________________________________\n",
            "MP (MaxPooling2D)            (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv_5 (Conv2D)              (None, 9, 9, 10)          900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_6 (Conv2D)              (None, 7, 7, 10)          900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv_7 (Conv2D)              (None, 5, 5, 12)          1080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 12)          48        \n",
            "_________________________________________________________________\n",
            "conv_8_1x1 (Conv2D)          (None, 5, 5, 10)          120       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 5, 5, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv_9 (Conv2D)              (None, 1, 1, 10)          2500      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,026\n",
            "Trainable params: 7,858\n",
            "Non-trainable params: 168\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\", use_bias=False)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MSbJEfeWDhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLHrZSAtWEFa",
        "colab_type": "code",
        "outputId": "e115e7cc-907f-4c46-c5ac-e7574c2f8e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1801
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.2140 - acc: 0.9309 - val_loss: 0.0583 - val_acc: 0.9809\n",
            "Epoch 2/25\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0766 - acc: 0.9763 - val_loss: 0.0398 - val_acc: 0.9868\n",
            "Epoch 3/25\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0569 - acc: 0.9823 - val_loss: 0.0371 - val_acc: 0.9883\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0484 - acc: 0.9850 - val_loss: 0.0572 - val_acc: 0.9826\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0429 - acc: 0.9862 - val_loss: 0.0266 - val_acc: 0.9915\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0404 - acc: 0.9867 - val_loss: 0.0238 - val_acc: 0.9921\n",
            "Epoch 7/25\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 12s 199us/step - loss: 0.0369 - acc: 0.9883 - val_loss: 0.0217 - val_acc: 0.9931\n",
            "Epoch 8/25\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0322 - acc: 0.9895 - val_loss: 0.0223 - val_acc: 0.9926\n",
            "Epoch 9/25\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0317 - acc: 0.9902 - val_loss: 0.0248 - val_acc: 0.9925\n",
            "Epoch 10/25\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0226 - val_acc: 0.9926\n",
            "Epoch 11/25\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0227 - val_acc: 0.9925\n",
            "Epoch 12/25\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0258 - acc: 0.9918 - val_loss: 0.0210 - val_acc: 0.9935\n",
            "Epoch 13/25\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0245 - acc: 0.9919 - val_loss: 0.0205 - val_acc: 0.9941\n",
            "Epoch 14/25\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0248 - acc: 0.9922 - val_loss: 0.0240 - val_acc: 0.9925\n",
            "Epoch 15/25\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0216 - val_acc: 0.9934\n",
            "Epoch 16/25\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0194 - val_acc: 0.9935\n",
            "Epoch 17/25\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0209 - acc: 0.9933 - val_loss: 0.0214 - val_acc: 0.9931\n",
            "Epoch 18/25\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0209 - val_acc: 0.9929\n",
            "Epoch 19/25\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0212 - acc: 0.9933 - val_loss: 0.0203 - val_acc: 0.9934\n",
            "Epoch 20/25\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0200 - val_acc: 0.9936\n",
            "Epoch 21/25\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0215 - val_acc: 0.9932\n",
            "Epoch 22/25\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0194 - val_acc: 0.9943\n",
            "Epoch 23/25\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0206 - val_acc: 0.9941\n",
            "Epoch 24/25\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0180 - acc: 0.9943 - val_loss: 0.0208 - val_acc: 0.9936\n",
            "Epoch 25/25\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.0182 - acc: 0.9941 - val_loss: 0.0204 - val_acc: 0.9942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbebf1ef828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}