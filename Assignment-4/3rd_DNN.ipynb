{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3rd DNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0gOpQYQviLF",
        "colab_type": "text"
      },
      "source": [
        "# Version-3\n",
        "\n",
        "### Change1 - Dropout\n",
        "Added dropout layer after every transition block\n",
        "- Dropout 0.10 - 99.18% (11th epoch)\n",
        "- Dropout 0.20 - 99.36% (25th epoch)\n",
        "- Dropout 0.30 - 99.32% (21st epoch)\n",
        "\n",
        "### Change2 - Dropout after every layer\n",
        "- Tried adding dropout fater every layer but got the accuracy of 99.28%\n",
        "- After removing few dropout layers, got the acuracy of 99.30 %\n",
        "\n",
        "\n",
        "Summary:\n",
        "- Dropout after every transition block worked effectively\n",
        "- Dropout increses the validation accuracy from 99.07% to 99.36%\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "### Install Dependencies \n",
        "\n",
        "- To train the following network, we use a framework named Keras.\n",
        "- Keras provides functions for Convolution layers, Activation layers, MaxPooling layer, etc. so we don't need write code for designing such layers. Instead we can focus on creating better network architecture\n",
        "- Following lines of code installs Keras on the system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "f1980e8a-0094-41b5-84db-e8d40e0a4d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_6H50FBVsld",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries and Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Numpy for matrices and multi-dimensional array's processing\n",
        "import numpy as np\n",
        "\n",
        "# Import Sequential to write model layer-by-layer in sequence \n",
        "from keras.models import Sequential\n",
        "\n",
        "# Import Flatten layer to flatten feature-map, Dropout to avoid overfitting\n",
        "from keras.layers import Flatten, Dropout, Activation, BatchNormalization\n",
        "\n",
        "# Import Convolution layer to perform convolution on the channels, MaxPooling to reduce dimensions of channel\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "\n",
        "# Import np_utils for one-hot-encoding\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Import hand written dataset of numbers from 0-9\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "The data is loaded in following variables:\n",
        "\n",
        "- X_train: Samples used during training the network\n",
        "- y_train: Corresponding labels for training data\n",
        "- X_test: Samples used for validation after training the network\n",
        "- y_test: Corresponding labels for the validation of network's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "373753f1-9086-4fcb-bc11-3272ab6f9fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxIXgp8xYNXF",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Information and Display Data Sample\n",
        "- We have 60000 images in training dataset\n",
        "- We have 10000 images in the testing dataset\n",
        "- Each image's dimension are 28x28x1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "c1c61923-6f65-4eae-8e40-5a37d00214ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Dimensions of the training dataset images\n",
        "print (X_train.shape)\n",
        "\n",
        "# Dimensions of the testing dataset images\n",
        "print (X_test.shape)\n",
        "\n",
        "# Import python module for plotting the image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Below line is written to display an image in this notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting first image in the training dataset\n",
        "# cmap='gray' displays the data sample in appropriate color space\n",
        "plt.imshow(X_train[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac96d48240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKorE7Q0ZOZY",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the dataset\n",
        "- Keras requires the input data in a form of 4D tensor\n",
        "- The first value represents the total number of images in a training/testing dataset\n",
        "- Second and third values are dimensions of an image\n",
        "- Fourth value is the number of channels (1 for grayscale and 3 for RGB)  \n",
        "\n",
        "Thus, the X_train will have a shape of (60000, 28, 28, 1)  \n",
        "and the X_test will have a shape of (1000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yaQcS6aZnte",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing the Data\n",
        "- When a Kernel is convolved over an input image, the maximum pixel value in the feature-map depends upon the maximum pixel value in the kernel\n",
        "- Different kernels will have different maximum values and so their corresponding feature-maps will have different maximum values\n",
        "- The feature-map with greater maximum pixel value will be louder while training the network\n",
        "- To avoid biased activations of such kernels, we perform Normalization\n",
        "- For normalization, we first convert the data into float so that we can get all the decimal values\n",
        "- By dividing all the pixels by 255, all the pixel values will be restricted between 0.0 to 1.0. This is how we normalize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFzfX0QqZ9HS",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "3f11d7a8-d866-4ecb-eff8-b2c9927366bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhFS2uM3aDEh",
        "colab_type": "text"
      },
      "source": [
        "### One-Hot Encoding\n",
        "- It is way of representing labels\n",
        "- Instead of using one-single scalar for labels, we use a vector to represent the labels.\n",
        "- The position of the ground-truth is marked as 1 while other positions are marked as 0\n",
        "- The network cannot print out the prediction as 0,1,2,....9\n",
        "- Instead it can activate the neuron associated with these numbers. So, the last layer before activation layer has number of neurons equal to number of classes (in this case 10)\n",
        "- The neuron associated with the number is set as 1 while other neurons are set as 0. Following is the pattern in which encoding is done:  \n",
        "  - Number 0 is encoded as 1000000000  \n",
        "  - Number 1 is encoded as 0100000000  \n",
        "  - Number 2 is encoded as 0010000000  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "   .  \n",
        "  - Number 9 is encoded as 0000000001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yShor8IUaiT9",
        "colab_type": "text"
      },
      "source": [
        "### Print Labels after one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "bd7d57b1-f4bc-4e69-8cd3-e24a60daf3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spiB8iJDao-w",
        "colab_type": "text"
      },
      "source": [
        "### Model Architecture\n",
        "\n",
        "- Model is defined sequential\n",
        "- The model has convolution, maxpooling, flatten and softmax layers\n",
        "\n",
        "- **Convolution Layer:**\n",
        "  - It is a process of extracting features from a channel using a kernel (feature extractor)\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/5-3ConvolutionSmall.gif?raw=true)\n",
        "\n",
        "- **MaxPooling Layer:**\n",
        "  - It reduces the dimension of an channel. If we use MaxPooling of 2x2, dimension of an channel will become half of input channel\n",
        "  - It only passes the louder pixel value in the next layer\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%203/Files/maxpool.gif?raw=true)\n",
        "\n",
        "- **Softmax Layer:**\n",
        "  - It is like probability\n",
        "  - It gives score of a class between 0 and 1\n",
        "![](https://github.com/Shilpaj1994/Phase1_assignments/blob/master/Assignment%201/softmax.png?raw=true)\n",
        "\n",
        "- **Flatten Layer:**\n",
        "  - It flattens the input dimension\n",
        "  - Multiple 2D channels are converted into a vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SDuRDmjPuD-",
        "colab_type": "text"
      },
      "source": [
        "### Dropout after Transition Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_KR_t_XV9rk",
        "colab_type": "code",
        "outputId": "0666bf2f-2be3-4ef6-ae3b-f50ffeef0f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "drop = 0.2\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   # Layer 1: Input:28x28x01  |  Kernels:(3x3x01)x10  |  Output:26x26x10  |  Receptive Field:3x3 \n",
        "model.add(BatchNormalization())                                                               # Layer 2: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2'))                          # Layer 3: Input:26x26x10  |  Kernels:(3x3x10)x10  |  Output:24x24x10  |  Receptive Field:5x5  \n",
        "model.add(BatchNormalization())                                                               # Layer 4: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3'))                          # Layer 5: Input:24x24x64  |  Kernels:(3x3x10)x12  |  Output:22x22x12  |  Receptive Field:7x7\n",
        "model.add(BatchNormalization())                                                               # Layer 6: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                      # Layer 7: Input:22x22x12  |  Kernels:(1x1x12)x10  |  Output:22x22x10  |  Receptive Field:7x7 \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         # Layer 8: Input:22x22x10  |    MaxPooling:(2x2)   |  Output:11x11x10  |  Receptive Field:14x14 \n",
        "model.add(BatchNormalization())                                                               # Layer 9: Batch Normalization\n",
        "model.add(Dropout(drop))                                                                      # Layer 10: Dropout Layer\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5'))                          # Layer 11: Input:11x11x10  |  Kernels:(3x3x10)x10  |  Output:9x9x10  |  Receptive Field:16x16 \n",
        "model.add(BatchNormalization())                                                               # Layer 12: Batch Normalization\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6'))                          # Layer 13: Input:09x09x10  |  Kernels:(3x3x10)x10  |  Output:7x7x10  |  Receptive Field:18x18 \n",
        "model.add(BatchNormalization())                                                               # Layer 14: Batch Normalization\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7'))                          # Layer 15: Input:07x07x10  |  Kernels:(3x3x10)x12  |  Output:5x5x12  |  Receptive Field:20x20 \n",
        "model.add(BatchNormalization())                                                               # Layer 16: Batch Normalization\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      # Layer 17: Input:5x5x12    |  Kernels:(1x1x12)x10  |  Output:5x5x10  |  Receptive Field:22x22\n",
        "model.add(BatchNormalization())                                                               # Layer 18: Batch Normalization\n",
        "model.add(Dropout(drop))                                                                      # Layer 19: Dropout Layer\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                # Layer 20: Input:5x5x10   |  Kernels:(5x5x10)x10  |  Output:1x1x10  |  Receptive Field:27x27 \n",
        "model.add(Flatten())                                                                          # Layer 21: Input:1x1x10   |  Output:10\n",
        "model.add(Activation('softmax'))                                                              # Layer 22: Activation Layer\n",
        "\n",
        "# Summaries above architecture\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MSbJEfeWDhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLHrZSAtWEFa",
        "colab_type": "code",
        "outputId": "051eada9-b9f8-4344-e9fc-bae6a373c0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.3655 - acc: 0.8819 - val_loss: 0.0819 - val_acc: 0.9738\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0962 - acc: 0.9701 - val_loss: 0.0576 - val_acc: 0.9809\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0700 - acc: 0.9779 - val_loss: 0.0456 - val_acc: 0.9850\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 21s 355us/step - loss: 0.0590 - acc: 0.9815 - val_loss: 0.0365 - val_acc: 0.9882\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 21s 355us/step - loss: 0.0512 - acc: 0.9843 - val_loss: 0.0343 - val_acc: 0.9890\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0488 - acc: 0.9843 - val_loss: 0.0336 - val_acc: 0.9891\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0380 - val_acc: 0.9882\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0407 - acc: 0.9869 - val_loss: 0.0279 - val_acc: 0.9902\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0402 - acc: 0.9874 - val_loss: 0.0376 - val_acc: 0.9884\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 21s 355us/step - loss: 0.0385 - acc: 0.9877 - val_loss: 0.0348 - val_acc: 0.9879\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0358 - acc: 0.9888 - val_loss: 0.0241 - val_acc: 0.9918\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0347 - acc: 0.9896 - val_loss: 0.0242 - val_acc: 0.9922\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0329 - acc: 0.9897 - val_loss: 0.0242 - val_acc: 0.9922\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0323 - acc: 0.9898 - val_loss: 0.0287 - val_acc: 0.9909\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0305 - acc: 0.9899 - val_loss: 0.0283 - val_acc: 0.9903\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0297 - acc: 0.9905 - val_loss: 0.0279 - val_acc: 0.9906\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0264 - val_acc: 0.9918\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0302 - acc: 0.9899 - val_loss: 0.0235 - val_acc: 0.9931\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 21s 357us/step - loss: 0.0273 - acc: 0.9914 - val_loss: 0.0274 - val_acc: 0.9920\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.0287 - val_acc: 0.9906\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 21s 353us/step - loss: 0.0274 - acc: 0.9908 - val_loss: 0.0246 - val_acc: 0.9921\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0247 - acc: 0.9917 - val_loss: 0.0247 - val_acc: 0.9928\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0254 - acc: 0.9918 - val_loss: 0.0247 - val_acc: 0.9919\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0230 - val_acc: 0.9932\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 21s 354us/step - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0241 - val_acc: 0.9927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac7b2fca20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9tcpTs8EzoR",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Dropout after every convoltion layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMyD2cDIbk0f",
        "colab_type": "code",
        "outputId": "df9c4666-dd4b-467b-e7e4-1a95d71cddd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "drop = 0.2\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2'))                          \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3'))                         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                     \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                        \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5'))                         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6'))                         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7'))                         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                     \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                               \n",
        "model.add(Flatten())                                                                         \n",
        "model.add(Activation('softmax'))                                                             \n",
        "\n",
        "# Summaries above architecture\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgFfuzStcAhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VlQILM8cDLe",
        "colab_type": "code",
        "outputId": "b291e771-3be5-4e14-89f9-66d8a6eb473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.5423 - acc: 0.8226 - val_loss: 0.1670 - val_acc: 0.9485\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.1723 - acc: 0.9461 - val_loss: 0.0784 - val_acc: 0.9763\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.1322 - acc: 0.9590 - val_loss: 0.0674 - val_acc: 0.9791\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.1086 - acc: 0.9661 - val_loss: 0.0813 - val_acc: 0.9750\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.1015 - acc: 0.9688 - val_loss: 0.0547 - val_acc: 0.9820\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0923 - acc: 0.9717 - val_loss: 0.0523 - val_acc: 0.9835\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0859 - acc: 0.9734 - val_loss: 0.0367 - val_acc: 0.9871\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 0.0826 - acc: 0.9747 - val_loss: 0.0373 - val_acc: 0.9888\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0812 - acc: 0.9752 - val_loss: 0.0334 - val_acc: 0.9891\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0761 - acc: 0.9765 - val_loss: 0.0461 - val_acc: 0.9861\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0714 - acc: 0.9779 - val_loss: 0.0334 - val_acc: 0.9904\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0710 - acc: 0.9776 - val_loss: 0.0329 - val_acc: 0.9891\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0701 - acc: 0.9778 - val_loss: 0.0285 - val_acc: 0.9914\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0652 - acc: 0.9804 - val_loss: 0.0332 - val_acc: 0.9893\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0671 - acc: 0.9798 - val_loss: 0.0274 - val_acc: 0.9924\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0622 - acc: 0.9808 - val_loss: 0.0340 - val_acc: 0.9888\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0630 - acc: 0.9806 - val_loss: 0.0295 - val_acc: 0.9905\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0609 - acc: 0.9804 - val_loss: 0.0344 - val_acc: 0.9897\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0611 - acc: 0.9815 - val_loss: 0.0322 - val_acc: 0.9909\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 0.0583 - acc: 0.9813 - val_loss: 0.0273 - val_acc: 0.9922\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0577 - acc: 0.9816 - val_loss: 0.0429 - val_acc: 0.9867\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0559 - acc: 0.9821 - val_loss: 0.0295 - val_acc: 0.9910\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0573 - acc: 0.9820 - val_loss: 0.0265 - val_acc: 0.9915\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0569 - acc: 0.9822 - val_loss: 0.0266 - val_acc: 0.9918\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0561 - acc: 0.9829 - val_loss: 0.0251 - val_acc: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac798c1da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29mkUmABswfz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Dropout in only convolution block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocvhBASqmKfV",
        "colab_type": "code",
        "outputId": "7e95c0a3-c4cb-4c71-c544-cd720a0da1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "# For reproducable results\n",
        "np.random.seed(7)\n",
        "\n",
        "drop = 0.2\n",
        "\n",
        "# Define Sequential Model Type\n",
        "model = Sequential()\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', input_shape=(28,28,1), name='conv_1'))   \n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_2'))                            \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_3'))                         \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_4_1x1'))                       \n",
        "model.add(MaxPooling2D(2, name='MP'))                                                         \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Convolution Block\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_5'))                           \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu', name='conv_6'))                         \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(drop))\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', name='conv_7'))                         \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Transition Block\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu', name='conv_8_1x1'))                      \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Output Block\n",
        "model.add(Convolution2D(10, 5, name='conv_9'))                                                \n",
        "model.add(Flatten())                                                                          \n",
        "model.add(Activation('softmax'))                                                              \n",
        "\n",
        "# Summaries above architecture\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., name=\"conv_1\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_2\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_3\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_4_1x1\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_5\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", name=\"conv_6\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", name=\"conv_7\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\", name=\"conv_8_1x1\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H3MeL8NmYjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-4nWCwmZpK",
        "colab_type": "code",
        "outputId": "0a98d700-d7b1-4632-a703-b6bead21dfe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "60000/60000 [==============================] - 25s 419us/step - loss: 0.3865 - acc: 0.8785 - val_loss: 0.0947 - val_acc: 0.9695\n",
            "Epoch 2/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.1084 - acc: 0.9665 - val_loss: 0.0605 - val_acc: 0.9800\n",
            "Epoch 3/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0796 - acc: 0.9750 - val_loss: 0.0472 - val_acc: 0.9842\n",
            "Epoch 4/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0665 - acc: 0.9789 - val_loss: 0.0456 - val_acc: 0.9851\n",
            "Epoch 5/25\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0609 - acc: 0.9808 - val_loss: 0.0338 - val_acc: 0.9896\n",
            "Epoch 6/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0553 - acc: 0.9830 - val_loss: 0.0332 - val_acc: 0.9902\n",
            "Epoch 7/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0490 - acc: 0.9846 - val_loss: 0.0340 - val_acc: 0.9895\n",
            "Epoch 8/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0464 - acc: 0.9851 - val_loss: 0.0293 - val_acc: 0.9914\n",
            "Epoch 9/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0449 - acc: 0.9858 - val_loss: 0.0318 - val_acc: 0.9898\n",
            "Epoch 10/25\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0422 - acc: 0.9872 - val_loss: 0.0299 - val_acc: 0.9908\n",
            "Epoch 11/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0397 - acc: 0.9872 - val_loss: 0.0353 - val_acc: 0.9891\n",
            "Epoch 12/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0386 - acc: 0.9877 - val_loss: 0.0364 - val_acc: 0.9889\n",
            "Epoch 13/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0359 - acc: 0.9884 - val_loss: 0.0270 - val_acc: 0.9919\n",
            "Epoch 14/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 0.0264 - val_acc: 0.9917\n",
            "Epoch 15/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0362 - acc: 0.9883 - val_loss: 0.0294 - val_acc: 0.9907\n",
            "Epoch 16/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0346 - acc: 0.9886 - val_loss: 0.0304 - val_acc: 0.9911\n",
            "Epoch 17/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0332 - acc: 0.9891 - val_loss: 0.0290 - val_acc: 0.9915\n",
            "Epoch 18/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0314 - acc: 0.9897 - val_loss: 0.0302 - val_acc: 0.9904\n",
            "Epoch 19/25\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0322 - acc: 0.9899 - val_loss: 0.0261 - val_acc: 0.9922\n",
            "Epoch 20/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0308 - acc: 0.9897 - val_loss: 0.0250 - val_acc: 0.9922\n",
            "Epoch 21/25\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0305 - acc: 0.9898 - val_loss: 0.0259 - val_acc: 0.9928\n",
            "Epoch 22/25\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0284 - acc: 0.9908 - val_loss: 0.0291 - val_acc: 0.9912\n",
            "Epoch 23/25\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0245 - val_acc: 0.9930\n",
            "Epoch 24/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0284 - acc: 0.9906 - val_loss: 0.0254 - val_acc: 0.9927\n",
            "Epoch 25/25\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0289 - acc: 0.9905 - val_loss: 0.0279 - val_acc: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac76303438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}